{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GymHwQB9GSYv"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "import keras.layers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from random import randint, choice, sample\n",
    "from copy import deepcopy\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)    # suppress messages from Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeUNKzZuGSZF"
   },
   "outputs": [],
   "source": [
    "def load_dataset(batch_size, num_classes, epochs):  \t\t\t\t\t# retrieve CIFAR10 dataset and process data\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\t\t\t\t\t\t\t\t\t# convert from integers to floats\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\t\t\t\t\t\t\t\t\t\t\t\t\t\t# normalize to range 0-1\n",
    "    x_test /= 255\n",
    "    y_train = to_categorical(y_train, num_classes)  \t\t\t\t\t# one-hot encoding\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    '''\t\t\t\t\t# uncomment to use small-data scenario\n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train[:4500],\n",
    "        'x_test': x_test[:500],\n",
    "        'y_train': y_train[:4500],\n",
    "        'y_test': y_test[:500]\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train,\n",
    "        'x_test': x_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_network(network):\n",
    "    object_file = open(network.name + '.obj', 'wb')\n",
    "    pickle.dump(network, object_file)\n",
    "\n",
    "\n",
    "def load_network(name):\n",
    "    object_file = open(name + '.obj', 'rb')\n",
    "    return pickle.load(object_file)\n",
    "\n",
    "\n",
    "def order_indexes(self):\n",
    "    i = 0\n",
    "    for block in self.block_list:\n",
    "        block.index = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def plot_training(history):\t\t\t\t\t\t\t\t\t\t\t\t# plot diagnostic learning curves\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# loss curves\n",
    "    plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
    "    plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.title('Loss Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_loss_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# accuracy curves\n",
    "    plt.plot(history.history['acc'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_acc'], 'b', linewidth=3.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_acc_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
    "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('FitnessValue', fontsize=16)\n",
    "    plt.title('Fitness Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_fitness_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
    "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('ParamsNum', fontsize=16)\n",
    "    plt.title('Parameters Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_params_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyZVEKvFGSZQ"
   },
   "outputs": [],
   "source": [
    "class Block:\n",
    "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
    "\n",
    "\tdef __init__(self, type, index, layerList1, layerList2):\n",
    "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
    "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
    "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
    "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
    "\n",
    "\tdef get_layers(self):\n",
    "\t\treturn self.layerList1 + self.layerList2\n",
    "\n",
    "\tdef get_size(self):\n",
    "\t\treturn len(self.get_layers())\n",
    "\n",
    "\n",
    "class Convolutional:\n",
    "\n",
    "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
    "\t\tself.name = 'Conv2D'\n",
    "\t\tself.filters = filters\n",
    "\t\tself.padding = padding\n",
    "\t\tself.filter_size = filter_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.input_shape = input_shape\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
    "\t\t\t\t\t\t\t\t\t   kernel_size=self.filter_size,\n",
    "\t\t\t\t\t\t\t\t\t   strides=self.stride_size,\n",
    "\t\t\t\t\t\t\t\t\t   padding=self.padding,\n",
    "\t\t\t\t\t\t\t\t\t   activation='relu',\n",
    "\t\t\t\t\t\t\t\t\t   kernel_initializer='he_uniform',\n",
    "\t\t\t\t\t\t\t\t\t   input_shape=self.input_shape))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 4)\n",
    "\t\tif mutation == 0 and self.filters >= 32:\n",
    "\t\t\tprint(\"changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters >= 32:\n",
    "\t\t\tprint(\"changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2 and self.filters <= 512:\n",
    "\t\t\tprint(\"changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 3 and self.filters <= 512:\n",
    "\t\t\tprint(\"changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 4:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
    "\n",
    "\tdef __init__(self, pool_size, stride_size, padding):\n",
    "\t\tself.name = 'MaxPooling2D'\n",
    "\t\tself.pool_size = pool_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.padding = padding\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\t\telif self.name == 'AveragePooling2D':\n",
    "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 1)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\t\tprint(\"changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'AveragePooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'MaxPooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\n",
    "\n",
    "class FullyConnected:\n",
    "\t__slots__ = ('name', 'units', 'num_classes')\n",
    "\n",
    "\tdef __init__(self, units, num_classes):\n",
    "\t\tself.name = \"FullyConnected\"\n",
    "\t\tself.units = units\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Flatten())\n",
    "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
    "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 2)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tself.units *= 2\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tself.units *= 2\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tself.units /= 2\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "\t__slots__ = ('name', 'rate')\n",
    "\n",
    "\tdef __init__(self, rate):\n",
    "\t\tself.name = \"Dropout\"\n",
    "\t\tself.rate = rate\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 3)\n",
    "\t\tif mutation == 0 and self.rate <= 0.85:\n",
    "\t\t\tprint(\"changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 1 and self.rate <= 0.90:\n",
    "\t\t\tprint(\"changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 2 and self.rate >= 0.15:\n",
    "\t\t\tprint(\"changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 3 and self.rate >= 0.10:\n",
    "\t\t\tprint(\"changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.05\n",
    "\t\t\tprint(\"to \", self.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRNemc-uGSZZ"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
    "        self.block_list = []\n",
    "        self.fitness = None\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()                                # create model\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():                # build model\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                except:\n",
    "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
    "                    return -1\n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self, model, dataset):\n",
    "        opt = SGD(lr=0.001, momentum=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=dataset['epochs'],\n",
    "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                            shuffle=True)\n",
    "\n",
    "        self.model = model                                  # model\n",
    "        self.fitness = history.history['val_loss'][-1]      # fitness\n",
    "        model.save(self.name + '.h5')                       # save model\n",
    "        save_network(self)                                  # save topology, model and fitness\n",
    "\n",
    "    def asexual_reproduction(self, it, dataset):\n",
    "\n",
    "        # if the individual already exists, just load it\n",
    "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
    "            individual = load_network('net_' + str(it))\n",
    "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
    "            return individual\n",
    "\n",
    "        # otherwise, create the individual by mutating the parent\n",
    "        individual = Network(it)\n",
    "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
    "\n",
    "        individual.block_mutation(dataset)                          # mutate a block\n",
    "        individual.layer_mutation(dataset)                          # mutate a layer\n",
    "        individual.parameters_mutation()                            # mutate some parameters\n",
    "\n",
    "        model = individual.build_model()\n",
    "\n",
    "        if model == -1:\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "\n",
    "        individual.train_and_evaluate(model, dataset)\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def block_mutation(self, dataset):\n",
    "        print(\"Mutating a block of\", self.name)\n",
    "\n",
    "        print([(block.index, block.type) for block in self.block_list])\n",
    "\n",
    "        # block list containing all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
    "            self.block_list[1].index = 2\n",
    "            layerList1 = [\n",
    "                Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                              filter_size=(3, 3),\n",
    "                              stride_size=(1, 1),\n",
    "                              padding='same',\n",
    "                              input_shape=dataset['x_train'].shape[1:]),\n",
    "                Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                              filter_size=(3, 3),\n",
    "                              stride_size=(1, 1),\n",
    "                              padding='same',\n",
    "                              input_shape=dataset['x_train'].shape[1:])\n",
    "            ]\n",
    "            layerList2 = [\n",
    "                Pooling(pool_size=(2, 2),\n",
    "                        stride_size=(2, 2),\n",
    "                        padding='same')\n",
    "            ]\n",
    "            b = Block(1, 1, layerList1, layerList2)\n",
    "            self.block_list.insert(1, b)\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
    "        block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "        mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "        length = len(layerList)\n",
    "\n",
    "        if mutation_type:                                       # remove\n",
    "            if length == 1:\n",
    "                del self.block_list[block_idx]\n",
    "            elif block_type_idx:\n",
    "                pos = randint(0, length - 1)\n",
    "                print(\"Removing a Conv2D layer at\", pos)\n",
    "                del layerList[pos]\n",
    "            else:\n",
    "                pos = randint(0, length - 1)\n",
    "                print(\"Removing a Pooling/Dropout layer at\", pos)\n",
    "                del layerList[pos]\n",
    "        else:                                                   # add\n",
    "            if block_type_idx:\n",
    "                print(\"Inserting a Convolutional layer\")\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                layerList.insert(randint(0, length - 1), layer)\n",
    "            else:\n",
    "                if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
    "                    print(\"Inserting a Pooling layer\")\n",
    "                    layer = Pooling(pool_size=(2, 2),\n",
    "                                    stride_size=(2, 2),\n",
    "                                    padding='same')\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "                else:\n",
    "                    print(\"Inserting a Dropout layer\")\n",
    "                    rate = choice([0.15, 0.25, 0.35, 0.50])\n",
    "                    layer = Dropout(rate=rate)\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "\n",
    "    def layer_mutation(self, dataset):\n",
    "        print(\"Mutating a layer of\", self.name)\n",
    "\n",
    "        # pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "                return\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "\n",
    "        idx = randint(0, len(layerList) - 1)\n",
    "        layer = layerList[idx]\n",
    "\n",
    "        if layer.name == 'Conv2D':\n",
    "            print(\"Splitting Conv2D layer at index\", idx)\n",
    "            layer.filters = int(layer.filters * 0.5)\n",
    "            layerList.insert(idx, deepcopy(layer))\n",
    "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
    "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
    "            del layerList[idx]\n",
    "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                       filter_size=(3, 3),\n",
    "                                       stride_size=(2, 2),\n",
    "                                       padding=layer.padding,\n",
    "                                       input_shape=dataset['x_train'].shape[1:])\n",
    "            layerList.insert(idx, conv_layer)\n",
    "\n",
    "    def parameters_mutation(self):\n",
    "        print(\"Mutating the parameters\", self.name)\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():\n",
    "                if randint(0, 1):\n",
    "                    layer.mutate_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su-_cVTnGSZg"
   },
   "outputs": [],
   "source": [
    "def compute_parent(dataset):\n",
    "    if os.path.isfile('parent_0.h5'):\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        return daddy\n",
    "\n",
    "    daddy = Network(0)\n",
    "\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
    "    '''                   # keep this commented to use VGG-1 model\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "        # Dropout(rate=0.25)\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "    \n",
    "    layerList1 = [\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same'),\n",
    "        Dropout(rate=0.25)\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "    '''\n",
    "    layerList1 = [\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 1, layerList1, layerList2))\n",
    "\n",
    "    model = daddy.build_model()\n",
    "    daddy.train_and_evaluate(model, dataset)\n",
    "    return daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3wYTaJcnGSZl",
    "outputId": "9db5f580-4b98-4ef4-8266-210cf793a18f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 4s 854us/step - loss: 1.3265 - acc: 0.5240 - val_loss: 1.5000 - val_acc: 0.4800\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 4s 868us/step - loss: 1.2453 - acc: 0.5569 - val_loss: 1.5234 - val_acc: 0.4700\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 4s 834us/step - loss: 1.1783 - acc: 0.5867 - val_loss: 1.4638 - val_acc: 0.4920\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 4s 842us/step - loss: 1.0705 - acc: 0.6238 - val_loss: 1.5391 - val_acc: 0.4440\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 4s 847us/step - loss: 0.9674 - acc: 0.6636 - val_loss: 1.5076 - val_acc: 0.4980\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 4s 834us/step - loss: 0.8913 - acc: 0.6873 - val_loss: 1.4784 - val_acc: 0.4960\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 4s 843us/step - loss: 0.7749 - acc: 0.7340 - val_loss: 1.6402 - val_acc: 0.5020\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 4s 842us/step - loss: 0.6809 - acc: 0.7747 - val_loss: 1.6549 - val_acc: 0.4700\n",
      "Mutating a block of net_5\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_5\n",
      "Splitting Conv2D layer at index 1\n",
      "Mutating the parameters net_5\n",
      "changed self.filters from  32  to  16\n",
      "changed self.filters from  32  to  64\n",
      "changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  16  to  32\n",
      "changed self.padding from  same  to  valid\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 2.2580 - acc: 0.1511 - val_loss: 2.1722 - val_acc: 0.1760\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 713us/step - loss: 2.0616 - acc: 0.2491 - val_loss: 2.0446 - val_acc: 0.2200\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 721us/step - loss: 1.9107 - acc: 0.3102 - val_loss: 1.8677 - val_acc: 0.3040\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 713us/step - loss: 1.8011 - acc: 0.3520 - val_loss: 1.8492 - val_acc: 0.3220\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 698us/step - loss: 1.7120 - acc: 0.3764 - val_loss: 1.7636 - val_acc: 0.3140\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 711us/step - loss: 1.6138 - acc: 0.4176 - val_loss: 1.6872 - val_acc: 0.3440\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 665us/step - loss: 1.5610 - acc: 0.4411 - val_loss: 1.7364 - val_acc: 0.3500\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 656us/step - loss: 1.5192 - acc: 0.4558 - val_loss: 1.6588 - val_acc: 0.3800\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 691us/step - loss: 1.4676 - acc: 0.4680 - val_loss: 1.6887 - val_acc: 0.3700\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 694us/step - loss: 1.4247 - acc: 0.4878 - val_loss: 1.6159 - val_acc: 0.3720\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 684us/step - loss: 1.3936 - acc: 0.5007 - val_loss: 1.6159 - val_acc: 0.3820\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 672us/step - loss: 1.3473 - acc: 0.5156 - val_loss: 1.5757 - val_acc: 0.3840\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 705us/step - loss: 1.3168 - acc: 0.5324 - val_loss: 1.5811 - val_acc: 0.4060\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 743us/step - loss: 1.2723 - acc: 0.5471 - val_loss: 1.5467 - val_acc: 0.4300\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 725us/step - loss: 1.2441 - acc: 0.5613 - val_loss: 1.5330 - val_acc: 0.4220\n",
      "Mutating a block of net_6\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_6\n",
      "Splitting Conv2D layer at index 1\n",
      "Mutating the parameters net_6\n",
      "changed self.filters from  32  to  16\n",
      "changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "changed self.filters from  256  to  128\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 2.2124 - acc: 0.1718 - val_loss: 2.0609 - val_acc: 0.2260\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 682us/step - loss: 1.9746 - acc: 0.2678 - val_loss: 1.9468 - val_acc: 0.3080\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 649us/step - loss: 1.8241 - acc: 0.3400 - val_loss: 1.7935 - val_acc: 0.3380\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 677us/step - loss: 1.7276 - acc: 0.3802 - val_loss: 1.7588 - val_acc: 0.3800\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 608us/step - loss: 1.6421 - acc: 0.4033 - val_loss: 1.6805 - val_acc: 0.3920\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 602us/step - loss: 1.5899 - acc: 0.4262 - val_loss: 1.6496 - val_acc: 0.4140\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 637us/step - loss: 1.5322 - acc: 0.4484 - val_loss: 1.6119 - val_acc: 0.4180\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 632us/step - loss: 1.4861 - acc: 0.4600 - val_loss: 1.6590 - val_acc: 0.3940\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 593us/step - loss: 1.4609 - acc: 0.4749 - val_loss: 1.6303 - val_acc: 0.4040\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 592us/step - loss: 1.4004 - acc: 0.4967 - val_loss: 1.5988 - val_acc: 0.4020\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 604us/step - loss: 1.3755 - acc: 0.5091 - val_loss: 1.5747 - val_acc: 0.4260\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 695us/step - loss: 1.3390 - acc: 0.5196 - val_loss: 1.6270 - val_acc: 0.4160\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 687us/step - loss: 1.2928 - acc: 0.5391 - val_loss: 1.5359 - val_acc: 0.4420\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 726us/step - loss: 1.2457 - acc: 0.5516 - val_loss: 1.5368 - val_acc: 0.4640\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 717us/step - loss: 1.2033 - acc: 0.5684 - val_loss: 1.5663 - val_acc: 0.4560\n",
      "Mutating a block of net_7\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_7\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_7\n",
      "changed self.filters from  32  to  16\n",
      "changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "changed self.filters from  32  to  64\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.1477 - acc: 0.2131 - val_loss: 1.9904 - val_acc: 0.2500\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 667us/step - loss: 1.8701 - acc: 0.3256 - val_loss: 1.8452 - val_acc: 0.3300\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 666us/step - loss: 1.7764 - acc: 0.3587 - val_loss: 1.8035 - val_acc: 0.3440\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 629us/step - loss: 1.6403 - acc: 0.4187 - val_loss: 1.6543 - val_acc: 0.4000\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 635us/step - loss: 1.5539 - acc: 0.4504 - val_loss: 1.6438 - val_acc: 0.3880\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 643us/step - loss: 1.5085 - acc: 0.4693 - val_loss: 1.6707 - val_acc: 0.3800\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 581us/step - loss: 1.4496 - acc: 0.4849 - val_loss: 1.7051 - val_acc: 0.3900\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 632us/step - loss: 1.3794 - acc: 0.5129 - val_loss: 1.6135 - val_acc: 0.4060\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 614us/step - loss: 1.3039 - acc: 0.5478 - val_loss: 1.5970 - val_acc: 0.4480\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 613us/step - loss: 1.2359 - acc: 0.5556 - val_loss: 1.5931 - val_acc: 0.4440\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 664us/step - loss: 1.1694 - acc: 0.5947 - val_loss: 1.6109 - val_acc: 0.4140\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 643us/step - loss: 1.0547 - acc: 0.6340 - val_loss: 1.5809 - val_acc: 0.4500\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 613us/step - loss: 0.9568 - acc: 0.6736 - val_loss: 1.5508 - val_acc: 0.4480\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 624us/step - loss: 0.8599 - acc: 0.7024 - val_loss: 1.6565 - val_acc: 0.4340\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 567us/step - loss: 0.7564 - acc: 0.7409 - val_loss: 1.6918 - val_acc: 0.4540\n",
      "Mutating a block of net_8\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_8\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_8\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  32  to  16\n",
      "changed self.filters from  64  to  32\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "Mutating a block of net_8\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_8\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_8\n",
      "changed self.padding from  valid  to  same\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  256  to  512\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 2.0864 - acc: 0.2200 - val_loss: 1.9100 - val_acc: 0.3180\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.7770 - acc: 0.3567 - val_loss: 1.7215 - val_acc: 0.3620\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.6355 - acc: 0.4064 - val_loss: 1.8802 - val_acc: 0.3400\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.5458 - acc: 0.4424 - val_loss: 1.6599 - val_acc: 0.3800\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 4s 979us/step - loss: 1.4507 - acc: 0.4918 - val_loss: 1.6690 - val_acc: 0.4100\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.3775 - acc: 0.5149 - val_loss: 1.5694 - val_acc: 0.4140\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.2991 - acc: 0.5444 - val_loss: 1.5682 - val_acc: 0.4080\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.1994 - acc: 0.5724 - val_loss: 1.6536 - val_acc: 0.3960\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 1.0850 - acc: 0.6187 - val_loss: 1.5584 - val_acc: 0.4260\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.9540 - acc: 0.6696 - val_loss: 1.6089 - val_acc: 0.4540\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.8224 - acc: 0.7171 - val_loss: 1.6290 - val_acc: 0.4360\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.7084 - acc: 0.7664 - val_loss: 1.7307 - val_acc: 0.4480\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.5744 - acc: 0.8140 - val_loss: 1.7193 - val_acc: 0.4300\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 4s 995us/step - loss: 0.4530 - acc: 0.8549 - val_loss: 1.9256 - val_acc: 0.4400\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.3456 - acc: 0.8933 - val_loss: 2.1839 - val_acc: 0.4320\n",
      "Mutating a block of net_9\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Mutating a layer of net_9\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_9\n",
      "changed self.filters from  32  to  64\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.padding from  same  to  valid\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 2.0979 - acc: 0.2344 - val_loss: 2.0175 - val_acc: 0.2560\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 766us/step - loss: 1.8212 - acc: 0.3369 - val_loss: 1.7985 - val_acc: 0.3560\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 777us/step - loss: 1.6496 - acc: 0.4000 - val_loss: 1.6499 - val_acc: 0.3920\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 739us/step - loss: 1.5674 - acc: 0.4373 - val_loss: 1.6702 - val_acc: 0.3780\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 679us/step - loss: 1.4644 - acc: 0.4729 - val_loss: 1.5578 - val_acc: 0.4220\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 672us/step - loss: 1.3719 - acc: 0.5109 - val_loss: 1.5382 - val_acc: 0.4400\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 705us/step - loss: 1.2935 - acc: 0.5453 - val_loss: 1.4902 - val_acc: 0.4660\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 753us/step - loss: 1.1989 - acc: 0.5764 - val_loss: 1.6244 - val_acc: 0.4580\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 748us/step - loss: 1.1062 - acc: 0.6098 - val_loss: 1.5619 - val_acc: 0.4760\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 723us/step - loss: 1.0285 - acc: 0.6473 - val_loss: 1.4594 - val_acc: 0.4860\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 726us/step - loss: 0.9289 - acc: 0.6809 - val_loss: 1.6590 - val_acc: 0.4400\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 730us/step - loss: 0.7975 - acc: 0.7229 - val_loss: 1.5809 - val_acc: 0.4820\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 730us/step - loss: 0.7012 - acc: 0.7600 - val_loss: 1.5470 - val_acc: 0.5060\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 741us/step - loss: 0.5972 - acc: 0.8042 - val_loss: 1.5551 - val_acc: 0.5020\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 694us/step - loss: 0.4654 - acc: 0.8520 - val_loss: 1.6165 - val_acc: 0.4960\n",
      "\n",
      "-------------------------------------\n",
      "parent_0 :  1.5315509300231933\n",
      "net_5 :  1.533006244659424\n",
      "net_6 :  1.5662783603668213\n",
      "net_1 :  1.5804131631851197\n",
      "net_2 :  1.6046912965774536\n",
      "net_9 :  1.6164673709869384\n",
      "net_4 :  1.6548909435272217\n",
      "net_7 :  1.691785309791565\n",
      "net_8 :  2.183943552970886\n",
      "net_3 :  2.3463614683151244\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Generation 1\n",
      "-------------------------------------\n",
      "\n",
      "--------> Creating child 0\n",
      "Proportionate selection\n",
      "Selected net_1 and net_4\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_10\n",
      "Splitting Conv2D layer at index 2\n",
      "Mutating the parameters net_10\n",
      "changed self.filters from  32  to  64\n",
      "changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.1431 - acc: 0.2156 - val_loss: 1.9463 - val_acc: 0.3200\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 4s 859us/step - loss: 1.8681 - acc: 0.3333 - val_loss: 1.7896 - val_acc: 0.3380\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 4s 923us/step - loss: 1.7351 - acc: 0.3689 - val_loss: 1.7529 - val_acc: 0.3660\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 4s 915us/step - loss: 1.6267 - acc: 0.4222 - val_loss: 1.6475 - val_acc: 0.4000\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 4s 954us/step - loss: 1.5788 - acc: 0.4244 - val_loss: 1.7063 - val_acc: 0.3820\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 4s 873us/step - loss: 1.4907 - acc: 0.4656 - val_loss: 1.6005 - val_acc: 0.4160\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 4s 877us/step - loss: 1.4079 - acc: 0.4973 - val_loss: 1.6340 - val_acc: 0.4300\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 4s 860us/step - loss: 1.3293 - acc: 0.5242 - val_loss: 1.6321 - val_acc: 0.4260\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 4s 887us/step - loss: 1.2701 - acc: 0.5378 - val_loss: 1.6101 - val_acc: 0.4120\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 4s 852us/step - loss: 1.2147 - acc: 0.5693 - val_loss: 1.5642 - val_acc: 0.4380\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 4s 898us/step - loss: 1.1467 - acc: 0.5936 - val_loss: 1.4993 - val_acc: 0.4680\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 4s 932us/step - loss: 1.0388 - acc: 0.6284 - val_loss: 1.5693 - val_acc: 0.4680\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 4s 919us/step - loss: 0.9819 - acc: 0.6522 - val_loss: 1.6976 - val_acc: 0.4440\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 4s 911us/step - loss: 0.8702 - acc: 0.6909 - val_loss: 1.6205 - val_acc: 0.4740\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 4s 922us/step - loss: 0.7771 - acc: 0.7284 - val_loss: 1.7594 - val_acc: 0.4280\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_10 with fitness 1.75937269115448 replaces parent net_3 with fitness 2.3463614683151244\n",
      "\n",
      "--------> Creating child 1\n",
      "Proportionate selection\n",
      "Selected net_4 and net_6\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_11\n",
      "Splitting Conv2D layer at index 1\n",
      "Mutating the parameters net_11\n",
      "changed self.filters from  32  to  16\n",
      "changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.2716 - acc: 0.1531 - val_loss: 2.1981 - val_acc: 0.2020\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 635us/step - loss: 2.1144 - acc: 0.2169 - val_loss: 2.0120 - val_acc: 0.2620\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 642us/step - loss: 1.9539 - acc: 0.2800 - val_loss: 1.8987 - val_acc: 0.3260\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 630us/step - loss: 1.8640 - acc: 0.3180 - val_loss: 1.8436 - val_acc: 0.3400\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 697us/step - loss: 1.7647 - acc: 0.3538 - val_loss: 1.7971 - val_acc: 0.3260\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 634us/step - loss: 1.7355 - acc: 0.3627 - val_loss: 1.7086 - val_acc: 0.3820\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 645us/step - loss: 1.6495 - acc: 0.4038 - val_loss: 1.6740 - val_acc: 0.3560\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 704us/step - loss: 1.6074 - acc: 0.4216 - val_loss: 1.5938 - val_acc: 0.3840\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 687us/step - loss: 1.5569 - acc: 0.4340 - val_loss: 1.6162 - val_acc: 0.4120\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 704us/step - loss: 1.5352 - acc: 0.4471 - val_loss: 1.5723 - val_acc: 0.4240\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 721us/step - loss: 1.4786 - acc: 0.4733 - val_loss: 1.5453 - val_acc: 0.4500\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 662us/step - loss: 1.4406 - acc: 0.4904 - val_loss: 1.5152 - val_acc: 0.4560\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 693us/step - loss: 1.3809 - acc: 0.5044 - val_loss: 1.5093 - val_acc: 0.4420\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 703us/step - loss: 1.3535 - acc: 0.5213 - val_loss: 1.5260 - val_acc: 0.4380\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 695us/step - loss: 1.3076 - acc: 0.5378 - val_loss: 1.5430 - val_acc: 0.4260\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_11 with fitness 1.5430278558731079 replaces parent net_8 with fitness 2.183943552970886\n",
      "\n",
      "--------> Creating child 2\n",
      "Proportionate selection\n",
      "Selected net_2 and net_3\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_12\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_12\n",
      "changed self.filters from  64  to  32\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.1468 - acc: 0.2044 - val_loss: 1.9669 - val_acc: 0.2680\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 4s 840us/step - loss: 1.9272 - acc: 0.2996 - val_loss: 1.8527 - val_acc: 0.3420\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 4s 839us/step - loss: 1.7848 - acc: 0.3567 - val_loss: 1.7680 - val_acc: 0.3260\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 4s 849us/step - loss: 1.6869 - acc: 0.3993 - val_loss: 1.7439 - val_acc: 0.3480\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 4s 824us/step - loss: 1.6085 - acc: 0.4171 - val_loss: 1.6536 - val_acc: 0.4240\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 4s 828us/step - loss: 1.5368 - acc: 0.4498 - val_loss: 1.6068 - val_acc: 0.4120\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 4s 844us/step - loss: 1.4958 - acc: 0.4620 - val_loss: 1.6236 - val_acc: 0.4140\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 4s 857us/step - loss: 1.4089 - acc: 0.5024 - val_loss: 1.5695 - val_acc: 0.4300\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 4s 887us/step - loss: 1.3432 - acc: 0.5131 - val_loss: 1.5376 - val_acc: 0.4640\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 4s 866us/step - loss: 1.2766 - acc: 0.5436 - val_loss: 1.6930 - val_acc: 0.3820\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 4s 823us/step - loss: 1.2227 - acc: 0.5709 - val_loss: 1.5244 - val_acc: 0.4500\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 4s 876us/step - loss: 1.1151 - acc: 0.6071 - val_loss: 1.5724 - val_acc: 0.4720\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 4s 858us/step - loss: 1.0153 - acc: 0.6413 - val_loss: 1.6674 - val_acc: 0.4540\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 4s 921us/step - loss: 0.9382 - acc: 0.6702 - val_loss: 1.6142 - val_acc: 0.4620\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 4s 877us/step - loss: 0.8197 - acc: 0.7193 - val_loss: 1.8685 - val_acc: 0.4300\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_12 with fitness 1.8684979190826416 is discarded\n",
      "\n",
      "--------> Creating child 3\n",
      "Proportionate selection\n",
      "Selected net_4 and net_5\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_13\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_13\n",
      "changed self.filters from  64  to  32\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "Crossover\n",
      "Mutating a block of net_13\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Mutating a layer of net_13\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_13\n",
      "changed self.filters from  64  to  32\n",
      "changed self.filters from  32  to  16\n",
      "changed self.filters from  32  to  64\n",
      "changed self.padding from  valid  to  same\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.3019 - acc: 0.1118 - val_loss: 2.2566 - val_acc: 0.1600\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 591us/step - loss: 2.1602 - acc: 0.1982 - val_loss: 2.0715 - val_acc: 0.2340\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 676us/step - loss: 1.9812 - acc: 0.2816 - val_loss: 1.9670 - val_acc: 0.2900\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 660us/step - loss: 1.8504 - acc: 0.3331 - val_loss: 1.9035 - val_acc: 0.3120\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 646us/step - loss: 1.7530 - acc: 0.3569 - val_loss: 1.7975 - val_acc: 0.3580\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 627us/step - loss: 1.6900 - acc: 0.3862 - val_loss: 1.7122 - val_acc: 0.3980\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 595us/step - loss: 1.6397 - acc: 0.4058 - val_loss: 1.7093 - val_acc: 0.3800\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 571us/step - loss: 1.5749 - acc: 0.4451 - val_loss: 1.6923 - val_acc: 0.3440\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 589us/step - loss: 1.5343 - acc: 0.4456 - val_loss: 1.6572 - val_acc: 0.3660\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 606us/step - loss: 1.4927 - acc: 0.4651 - val_loss: 1.6731 - val_acc: 0.3740\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 608us/step - loss: 1.4711 - acc: 0.4740 - val_loss: 1.6999 - val_acc: 0.3660\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 618us/step - loss: 1.3954 - acc: 0.4976 - val_loss: 1.6303 - val_acc: 0.4180\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 578us/step - loss: 1.3548 - acc: 0.5167 - val_loss: 1.6432 - val_acc: 0.4180\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 590us/step - loss: 1.3261 - acc: 0.5273 - val_loss: 1.6469 - val_acc: 0.3980\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 601us/step - loss: 1.2758 - acc: 0.5436 - val_loss: 1.6745 - val_acc: 0.4220\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_13 with fitness 1.6745481433868408 replaces parent net_3 with fitness 1.75937269115448\n",
      "\n",
      "-------------------------------------\n",
      "Generation 2\n",
      "-------------------------------------\n",
      "\n",
      "--------> Creating child 0\n",
      "Proportionate selection\n",
      "Selected net_7 and net_6\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_10\n",
      "Splitting Conv2D layer at index 0\n",
      "Mutating the parameters net_10\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  32  to  16\n",
      "changed self.filters from  64  to  32\n",
      "changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 2.2955 - acc: 0.1060 - val_loss: 2.2470 - val_acc: 0.1680\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 574us/step - loss: 2.1315 - acc: 0.1960 - val_loss: 2.0291 - val_acc: 0.2020\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 591us/step - loss: 2.0078 - acc: 0.2451 - val_loss: 1.9149 - val_acc: 0.3080\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 581us/step - loss: 1.8628 - acc: 0.3133 - val_loss: 1.8950 - val_acc: 0.2860\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 592us/step - loss: 1.8226 - acc: 0.3436 - val_loss: 1.7457 - val_acc: 0.3760\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 588us/step - loss: 1.7227 - acc: 0.3698 - val_loss: 1.7632 - val_acc: 0.3500\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 588us/step - loss: 1.6633 - acc: 0.3907 - val_loss: 1.7075 - val_acc: 0.3680\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 587us/step - loss: 1.6229 - acc: 0.4053 - val_loss: 1.7039 - val_acc: 0.3920\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 587us/step - loss: 1.5751 - acc: 0.4247 - val_loss: 1.6399 - val_acc: 0.4120\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 584us/step - loss: 1.5299 - acc: 0.4482 - val_loss: 1.6583 - val_acc: 0.4140\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 585us/step - loss: 1.4984 - acc: 0.4433 - val_loss: 1.6499 - val_acc: 0.4000\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 589us/step - loss: 1.4662 - acc: 0.4580 - val_loss: 1.6034 - val_acc: 0.4320\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 581us/step - loss: 1.4043 - acc: 0.4780 - val_loss: 1.6256 - val_acc: 0.4200\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 593us/step - loss: 1.3574 - acc: 0.5058 - val_loss: 1.6049 - val_acc: 0.4200\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 591us/step - loss: 1.3042 - acc: 0.5167 - val_loss: 1.5860 - val_acc: 0.4360\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_10 with fitness 1.5859935302734376 replaces parent net_7 with fitness 1.691785309791565\n",
      "\n",
      "--------> Creating child 1\n",
      "Proportionate selection\n",
      "Selected net_1 and net_5\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_11\n",
      "Splitting Conv2D layer at index 1\n",
      "Mutating the parameters net_11\n",
      "changed self.filters from  16  to  32\n",
      "changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 2.3050 - acc: 0.1196 - val_loss: 2.2881 - val_acc: 0.1700\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 578us/step - loss: 2.2732 - acc: 0.1660 - val_loss: 2.2281 - val_acc: 0.2180\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 589us/step - loss: 2.1559 - acc: 0.2091 - val_loss: 2.1257 - val_acc: 0.2300\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 586us/step - loss: 1.9895 - acc: 0.2798 - val_loss: 2.0019 - val_acc: 0.2760\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 586us/step - loss: 1.8967 - acc: 0.3222 - val_loss: 1.9395 - val_acc: 0.3020\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 582us/step - loss: 1.8326 - acc: 0.3480 - val_loss: 1.9009 - val_acc: 0.2940\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 585us/step - loss: 1.7858 - acc: 0.3622 - val_loss: 1.8450 - val_acc: 0.2960\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 570us/step - loss: 1.7441 - acc: 0.3847 - val_loss: 1.8104 - val_acc: 0.3200\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 586us/step - loss: 1.6802 - acc: 0.3949 - val_loss: 1.7376 - val_acc: 0.3680\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 587us/step - loss: 1.6736 - acc: 0.3967 - val_loss: 1.7155 - val_acc: 0.3800\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 585us/step - loss: 1.5949 - acc: 0.4264 - val_loss: 1.7006 - val_acc: 0.3780\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 575us/step - loss: 1.5984 - acc: 0.4184 - val_loss: 1.6809 - val_acc: 0.3880\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 589us/step - loss: 1.5756 - acc: 0.4307 - val_loss: 1.6723 - val_acc: 0.3820\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 584us/step - loss: 1.5211 - acc: 0.4469 - val_loss: 1.6382 - val_acc: 0.4160\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 579us/step - loss: 1.4873 - acc: 0.4513 - val_loss: 1.6617 - val_acc: 0.3700\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_11 with fitness 1.661718999862671 replaces parent net_3 with fitness 1.6745481433868408\n",
      "\n",
      "--------> Creating child 2\n",
      "Proportionate selection\n",
      "Selected net_6 and net_1\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_12\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Mutating the parameters net_12\n",
      "changed self.padding from  valid  to  same\n",
      "changed self.filters from  32  to  16\n",
      "changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.1406 - acc: 0.2111 - val_loss: 2.0956 - val_acc: 0.2680\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 588us/step - loss: 1.8403 - acc: 0.3391 - val_loss: 1.7350 - val_acc: 0.3880\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 586us/step - loss: 1.6626 - acc: 0.3989 - val_loss: 1.6928 - val_acc: 0.3800\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 599us/step - loss: 1.5460 - acc: 0.4484 - val_loss: 1.5921 - val_acc: 0.4320\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 603us/step - loss: 1.4532 - acc: 0.4776 - val_loss: 1.5844 - val_acc: 0.4100\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 619us/step - loss: 1.3433 - acc: 0.5131 - val_loss: 1.5444 - val_acc: 0.4640\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 3s 600us/step - loss: 1.2466 - acc: 0.5484 - val_loss: 1.6450 - val_acc: 0.3920\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 609us/step - loss: 1.1602 - acc: 0.5927 - val_loss: 1.5423 - val_acc: 0.4640\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 601us/step - loss: 1.0246 - acc: 0.6358 - val_loss: 1.7763 - val_acc: 0.4260\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 609us/step - loss: 0.9413 - acc: 0.6704 - val_loss: 1.6817 - val_acc: 0.4460\n",
      "Epoch 11/15\n",
      "4500/4500 [==============================] - 3s 627us/step - loss: 0.7943 - acc: 0.7273 - val_loss: 1.6149 - val_acc: 0.4840\n",
      "Epoch 12/15\n",
      "4500/4500 [==============================] - 3s 593us/step - loss: 0.6215 - acc: 0.7864 - val_loss: 1.7895 - val_acc: 0.4540\n",
      "Epoch 13/15\n",
      "4500/4500 [==============================] - 3s 594us/step - loss: 0.5278 - acc: 0.8198 - val_loss: 1.8728 - val_acc: 0.4560\n",
      "Epoch 14/15\n",
      "4500/4500 [==============================] - 3s 591us/step - loss: 0.3559 - acc: 0.8889 - val_loss: 2.2409 - val_acc: 0.4260\n",
      "Epoch 15/15\n",
      "4500/4500 [==============================] - 3s 592us/step - loss: 0.2515 - acc: 0.9227 - val_loss: 2.3159 - val_acc: 0.4300\n",
      "Evaluation: Child has been built and evaluated\n",
      "Evolution: Child net_12 with fitness 2.3158609838485718 is discarded\n",
      "\n",
      "--------> Creating child 3\n",
      "Proportionate selection\n",
      "Selected net_4 and net_7\n",
      "Crossover\n",
      "Child has been created\n",
      "Mutating a layer of net_13\n",
      "Splitting Conv2D layer at index 0\n",
      "Mutating the parameters net_13\n",
      "changed self.padding from  same  to  valid\n",
      "changed self.filters from  64  to  32\n",
      "changed self.filters from  64  to  32\n",
      "changed self.filters from  16  to  32\n",
      "Child has been mutated\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 2.2977 - acc: 0.1042 - val_loss: 2.2437 - val_acc: 0.1520\n",
      "Epoch 2/15\n",
      "4500/4500 [==============================] - 3s 563us/step - loss: 2.1637 - acc: 0.1907 - val_loss: 2.0941 - val_acc: 0.1840\n",
      "Epoch 3/15\n",
      "4500/4500 [==============================] - 3s 560us/step - loss: 2.0387 - acc: 0.2476 - val_loss: 1.9904 - val_acc: 0.2800\n",
      "Epoch 4/15\n",
      "4500/4500 [==============================] - 3s 572us/step - loss: 1.9241 - acc: 0.3049 - val_loss: 1.9093 - val_acc: 0.2740\n",
      "Epoch 5/15\n",
      "4500/4500 [==============================] - 3s 565us/step - loss: 1.8334 - acc: 0.3458 - val_loss: 1.9308 - val_acc: 0.3140\n",
      "Epoch 6/15\n",
      "4500/4500 [==============================] - 3s 566us/step - loss: 1.8113 - acc: 0.3484 - val_loss: 1.8211 - val_acc: 0.3540\n",
      "Epoch 7/15\n",
      "4500/4500 [==============================] - 2s 553us/step - loss: 1.6876 - acc: 0.3880 - val_loss: 1.7084 - val_acc: 0.3780\n",
      "Epoch 8/15\n",
      "4500/4500 [==============================] - 3s 599us/step - loss: 1.6350 - acc: 0.4042 - val_loss: 1.8795 - val_acc: 0.3200\n",
      "Epoch 9/15\n",
      "4500/4500 [==============================] - 3s 577us/step - loss: 1.6005 - acc: 0.4120 - val_loss: 1.7753 - val_acc: 0.3740\n",
      "Epoch 10/15\n",
      "4500/4500 [==============================] - 3s 567us/step - loss: 1.5466 - acc: 0.4409 - val_loss: 1.6920 - val_acc: 0.3880\n",
      "Epoch 11/15\n",
      "2400/4500 [===============>..............] - ETA: 1s - loss: 1.4765 - acc: 0.4554"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f36dffa6e186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-f36dffa6e186>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# plot the best model obtained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0moptCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_population\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_generation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_offspring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Genetic Algorithm took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{0:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-f36dffa6e186>\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(num_population, num_generation, num_offspring, dataset)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation: Child has been built and evaluated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-63cac223e878>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, model, dataset)\u001b[0m\n\u001b[1;32m     28\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                             shuffle=True)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m                                  \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def initialize_population(population_size, dataset):\n",
    "    print(\"Initialize Population\")\n",
    "    daddy = compute_parent(dataset)                               # load parent from input\n",
    "    population = [daddy]\n",
    "    for it in range(1, population_size):\n",
    "        population.append(daddy.asexual_reproduction(it, dataset))\n",
    "\n",
    "    # sort population on ascending order based on fitness\n",
    "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
    "\n",
    "\n",
    "def selection(k, population, num_population):\n",
    "    if k == 0:                                                    # elitism selection\n",
    "        print(\"Elitism selection\")\n",
    "        return population[0], population[1]\n",
    "    elif k == 1:                                                  # tournament selection\n",
    "        print(\"Tournament selection\")\n",
    "        i = randint(0, num_population - 1)\n",
    "        j = i\n",
    "        while j < num_population - 1:\n",
    "            j += 1\n",
    "            if randint(1, 100) <= 50:\n",
    "                return population[i], population[j]\n",
    "        return population[i], population[0]\n",
    "    else:                                                         # proportionate selection\n",
    "        print(\"Proportionate selection\")\n",
    "        cum_sum = 0\n",
    "        for i in range(num_population):\n",
    "            cum_sum += population[i].fitness\n",
    "        perc_range = []\n",
    "        for i in range(num_population):\n",
    "            count = int(100 * population[i].fitness / cum_sum)\n",
    "            for j in range(count):\n",
    "                perc_range.append(i)\n",
    "        i, j = sample(range(1, len(perc_range)), 2)\n",
    "        while i == j:\n",
    "            i, j = sample(range(1, len(perc_range)), 2)\n",
    "        return population[perc_range[i]], population[perc_range[j]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, it):\n",
    "    print(\"Crossover\")\n",
    "    child = Network(it)\n",
    "\n",
    "    first, second = None, None\n",
    "    if randint(0, 1):\n",
    "        first = parent1\n",
    "        second = parent2\n",
    "    else:\n",
    "        first = parent2\n",
    "        second = parent1\n",
    "\n",
    "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
    "                     + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
    "\n",
    "    order_indexes(child)                        # order the indexes of the blocks\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(num_population, num_generation, num_offspring, dataset):\n",
    "    print(\"Genetic Algorithm\")\n",
    "\n",
    "    population = initialize_population(num_population, dataset)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    '''\n",
    "        k is the selection parameter:\n",
    "            k = 0 -> elitism selection\n",
    "            k = 1 -> tournament selection\n",
    "            k = 2 -> proportionate selection\n",
    "    '''\n",
    "    k = randint(0, 2)\n",
    "\n",
    "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
    "\n",
    "    for gen in range(1, num_generation + 1):\n",
    "\n",
    "        print(\"\\n-------------------------------------\")\n",
    "        print(\"Generation\", gen)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        for c in range(num_offspring):\n",
    "\n",
    "            print(\"\\n--------> Creating child\", c)\n",
    "\n",
    "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
    "            print(\"Selected\", parent1.name, \"and\", parent2.name)\n",
    "\n",
    "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
    "            print(\"Child has been created\")\n",
    "\n",
    "            child.layer_mutation(dataset)                                               # mutation\n",
    "            child.parameters_mutation()\n",
    "            print(\"Child has been mutated\")\n",
    "\n",
    "            model = child.build_model()                                                 # evaluation\n",
    "\n",
    "            while model == -1:\n",
    "                child = crossover(parent1, parent2, c + num_population)\n",
    "                child.block_mutation(dataset)\n",
    "                child.layer_mutation(dataset)\n",
    "                child.parameters_mutation()\n",
    "                model = child.build_model()\n",
    "\n",
    "            child.train_and_evaluate(model, dataset)\n",
    "            print(\"Evaluation: Child has been built and evaluated\")\n",
    "\n",
    "            # evolve population\n",
    "            if child.fitness < population[-1].fitness:\n",
    "                print(\"Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
    "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
    "                name = population[-1].name\n",
    "                population[-1] = deepcopy(child)\n",
    "                population[-1].name = name\n",
    "                population = sorted(population, key=lambda net: net.fitness)\n",
    "            else:\n",
    "                print(\"Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
    "\n",
    "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
    "\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    print(\"Final Population\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Stats\")\n",
    "    for s in stats:\n",
    "        print(s)\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
    "    plot_statistics(stats)\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 64             # the number of training examples in one forward/backward pass\n",
    "    num_classes = 10            # number of cifar-10 dataset classes\n",
    "    epochs = 50                 # number of forward and backward passes of all the training examples\n",
    "\n",
    "    '''\n",
    "        dataset contains the hyper parameters for loading data and the dataset:\n",
    "            dataset = {\n",
    "                'batch_size': batch_size,\n",
    "                'num_classes': num_classes,\n",
    "                'epochs': epochs,\n",
    "                'x_train': x_train,\n",
    "                'x_test': x_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test\n",
    "            }\n",
    "    '''\n",
    "    dataset = load_dataset(batch_size, num_classes, epochs)\n",
    "\n",
    "    num_population = 10\n",
    "    num_generation = 10\n",
    "    num_offspring = 10\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    # plot the best model obtained\n",
    "    optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
    "    \n",
    "    print(\"Genetic Algorithm took\", \"{0:.4f}\".format(time() - t0), \"seconds\")\n",
    "\n",
    "    # plot the training and validation loss and accuracy\n",
    "    num_epoch = 15\n",
    "    model = optCNN.build_model()\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(dataset['x_train'],\n",
    "                        dataset['y_train'],\n",
    "                        batch_size=dataset['batch_size'],\n",
    "                        epochs=num_epoch,\n",
    "                        validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                        shuffle=True)\n",
    "    optCNN.model = model                                                # model\n",
    "    optCNN.fitness = history.history['val_loss'][-1]                    # fitness\n",
    "\n",
    "    plot_training(history)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9BWS3iFMcXB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GeneticCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
